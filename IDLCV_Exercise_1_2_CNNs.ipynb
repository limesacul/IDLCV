{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW29Y96P5LrX"
   },
   "source": [
    "## Exercise 1.2\n",
    "## Classification of MNIST digits with a convolutional neural network\n",
    "\n",
    "In this exercise we will classify MNIST digits again, but this time we will use a convolutional neural network (CNN).\n",
    "\n",
    "First we import the modules we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jz2q4lHP5LrY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr5H-aka5Lrc"
   },
   "source": [
    "We check that this script has a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1Uvbi4IX5Lrc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9w4bzfX5Lrh"
   },
   "source": [
    "We import the MNIST dataset, which is built into pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yF0nU9c85Lri",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "testset = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PnRF_Ev5Lrm"
   },
   "source": [
    "You should implement a network to classify MNIST digits. \n",
    "The network should consist of two parts, a part with convolutions and one with fully connected layers.\n",
    "The convolutional part we will call `convolutional`, and it should contain the follwing:\n",
    "* two convolutional layers with 8 features\n",
    "* a $2\\times2$ max pooling layer\n",
    "* two convolutional layers with 16 features\n",
    "\n",
    "The convolutions should be $3\\times 3$, and should not change the size of the output. What does this mean that the stride and padding should be?\n",
    "\n",
    "For example check the documentation of the `nn` module https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "**Remember**: There's a specific type of layer that you should always have after a convolution or a fully connected layer. What is this type of layer called?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HqJTyYy35Lrn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, 3, 1, 1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(8, 8, 3, 1, 1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(8, 16, 3, 1, 1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, 1, 1),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(14*14*16, 500),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(500, 10),\n",
    "                nn.Softmax(dim=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKI3L0rh5Lrq"
   },
   "source": [
    "We instantiate a copy of our network, transfer it to the GPU if it's available.\n",
    "We also check if the dimensions of our network match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mD7N5AZA5Lrr",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Get the first minibatch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Try running the model on a minibatch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of the output from the convolutional part\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mconvolutional(data)\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model.to(device)\n",
    "#Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#Get the first minibatch\n",
    "data = next(iter(train_loader))[0].cuda()\n",
    "#Try running the model on a minibatch\n",
    "print('Shape of the output from the convolutional part', model.convolutional(data).shape)\n",
    "model(data); #if this runs the model dimensions fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCjfL-y_5Lru"
   },
   "source": [
    "We train this network for five epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyuQgHmE5Lrv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "    #For each epoch\n",
    "    train_correct = 0\n",
    "    for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #Zero the gradients computed for each weight\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass your image through the network\n",
    "        output = model(data)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(torch.log(output), target)\n",
    "        #Backward pass through the network\n",
    "        loss.backward()\n",
    "        #Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Compute how many were correctly classified\n",
    "        predicted = output.argmax(1)\n",
    "        train_correct += (target==predicted).sum().cpu().item()\n",
    "    #Comput the test accuracy\n",
    "    test_correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        predicted = output.argmax(1).cpu()\n",
    "        test_correct += (target==predicted).sum().item()\n",
    "    train_acc = train_correct/len(trainset)\n",
    "    test_acc = test_correct/len(testset)\n",
    "    print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoEC9oDH5Lr0"
   },
   "source": [
    "Hopefully you now have a model that's able to achieve decent performance on MNIST.\n",
    "It should have around 97.5% accuracy on the test set after the first epoch.\n",
    "\n",
    "* Why is the accuracy on the training set higher than on the test set? (recall from machine learning)\n",
    "\n",
    "* Why does it have higher accuracy on the test set than the training set after the first epoch?\n",
    "\n",
    "   hint: it's related to how the train accuracy is computed\n",
    "\n",
    "### Data augmentation\n",
    " * Add random rotations to the MNIST digits during training (you have to go back and modify the dataloader)\n",
    " \n",
    "  hint: you can use `transforms.RandomRotation` \n",
    "  \n",
    "  hint: you can combine multiple transforms into one with `transforms.Compose`\n",
    "\n",
    "How does this affect your training and testing loss?\n",
    "\n",
    " * Try plotting some of the augmented images, to visually confirm what your augmentation is doing.\n",
    "\n",
    " * Try adding another type of data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uf7eO8P5Lr1"
   },
   "source": [
    "### Explore the model\n",
    "What has the model learned? You can access all the weights in the model with `model.parameters()`. Here we just print the shape.\n",
    " - Try showing images of the filters in the first layer. \n",
    " - Can you from the dimensions of the weights alone identify which layer it is in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lkTsfgo5Lr1"
   },
   "outputs": [],
   "source": [
    "[w.shape for w in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0Fyc1SG5Lr4"
   },
   "source": [
    "### Dropout\n",
    " * Try adding dropout to your model.\n",
    " \n",
    "You can add it between the convolutional layers and or in the fully connected part.\n",
    "\n",
    "Remember to call `net.train()` and `net.eval()` to change the model from test to training state, so it knows when you want it to apply dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already done?\n",
    "\n",
    "Try to exploreextracting features at different layers of the model and visualizing the corresponding representation of your data using e.g. t-SNE or PCA. Try to understand how those two techniques differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 1.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
